{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VolumeSeug.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TemirlanKalim/SeugTest/blob/master/VolumeSeug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyheQtRjGnbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "data = pd.read_csv('TrainingDayVolume.csv',sep=';',skiprows=[0],names=['consumption_day','volume'],index_col=[0], engine='python') #Training Dataset (Больше данных - лучше)\n",
        "#data.head()\n",
        "scaler = MinMaxScaler(feature_range=(0, 1)) #задать границы трансформации\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecJWPwLbG7aB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = data.values\n",
        "dataset = dataset.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ini6D-GUd4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = scaler.fit_transform(dataset) #трансформировать датасет в 0-1\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset)) # тренировачный массив заданной длины\n",
        "#test_size = len(dataset) - train_size\n",
        "train = dataset[0:train_size,:] #создаем массив для тренировки модели\n",
        "#, test , dataset[train_size:len(dataset),:]\n",
        "#print(len(train), len(test))\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1, output_val): # функция для разбивки тренировачного датасета на инпут и аутпут\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-(output_val+1): #\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tb = dataset[(i+look_back):(i+look_back+output_val), 0] #\n",
        "\t\tdataY.append(b)\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 1800 #длина инпута\n",
        "output_val= 365\n",
        "trainX, trainY = create_dataset(train, look_back,output_val) # создание тренировочного инпута и аутпута\n",
        "#testX, testY = create_dataset(test, look_back,output_val)\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1])) #трансформация инпут массива в подходящий для модели\n",
        "#testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "# create and fit the LSTM network\n",
        "model = Sequential() #создание модели Stacked LSTM\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, look_back))) # 1 LSTM уровень модели\n",
        "model.add(LSTM(50, activation='relu')) # 2 LSTM уровень\n",
        "model.add(Dense(output_val)) #Выходной уровень модели\n",
        "model.compile(loss='mean_squared_error', optimizer='adam') #оптимизирование модели используя mean_squared_error и adam optimizer\n",
        "model.fit(trainX, trainY, epochs=20, batch_size=2, verbose=2) # Запуск модели\n",
        "# make predictions\n",
        "trainPredict = model.predict(trainX) # Прогноз для тестирования\n",
        "#testPredict = model.predict(testX)\n",
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict) # Обратная трансформация из 0-1 в привычный для прогноза\n",
        "trainY = scaler.inverse_transform(trainY) # братная трансформация из 0-1 в привычный для тренировочного аутпута\n",
        "#testPredict = scaler.inverse_transform(testPredict)\n",
        "#testY = scaler.inverse_transform(testY)\n",
        "# calculate root mean squared error\n",
        "#trainScore = math.sqrt(mean_squared_error(trainY[:,0], trainPredict[:,0])) #вывод точности модели\n",
        "#print('Train Score: %.2f RMSE' % (trainScore))\n",
        "#testScore = math.sqrt(mean_squared_error(testY[:,0], testPredict[:,0]))\n",
        "#print('Test Score: %.2f RMSE' % (testScore))\n",
        "#model.save('testmodel.h5') #сохранение модели в h5 формате\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoTk2cx1b0Ag",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtDqV5ajGeK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model=load_model('Volumemodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05Z3VZRdRPzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frame = pd.read_csv('output1fINAL.csv',sep=';',index_col=[0],usecols=[0,1,2,3,4,5], engine='python') #загрузка инпут датасета\n",
        "#frame,usecols=['consumption_day','volume']usecols=[0,1,2,3,4,5,6],"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upXzM-oSSAh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(51): #разбивка на 51 ПУ\n",
        "  frame1=frame.loc[1+i*2006:2006+2006*i-3]\n",
        "  frame1=frame1.tail(1800)\n",
        "  #print(frame1.tail(1))\n",
        "  frame1=frame1['volume']\n",
        "  frame1=numpy.reshape(frame1.values, (frame1.values.shape[0],1))\n",
        "  newset = frame1\n",
        "  newset = newset.astype('float32')\n",
        "  #print(newset)\n",
        "  newset=scaler.fit_transform(newset)\n",
        "  newset=numpy.reshape(newset, ( 1,1, newset.shape[0]))\n",
        "  #print(newset)\n",
        "  #print(newset.shape)\n",
        "  res=model.predict(newset)\n",
        "  #print(res.shape)\n",
        "  res=scaler.inverse_transform(res)\n",
        "  res=numpy.reshape(res, (res.shape[1], 1))\n",
        "  ress=pd.DataFrame(data=numpy.round(res),columns=['volume'])\n",
        "  ress['consumption_day'] = pd.date_range(start='6/27/2019', periods=len(ress), freq='D')\n",
        "  ress=ress.assign(**{'counterparty_siug_id': frame.loc[[1+i*2006],['counterparty_siug_id']].values[0][0], 'gas_control_point_siug_id': i+1, 'gas_counter_siug_id': i+1})\n",
        "  cols=ress.columns.tolist()\n",
        "  cols=[cols[2],cols[3],cols[4],cols[1],cols[0]]\n",
        "  ress=ress[cols]\n",
        "  name='PuNumVolume'+str(i+1)+'.csv'\n",
        "  ress.to_csv(name)\n",
        "  files.download(name) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}